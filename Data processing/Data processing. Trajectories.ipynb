{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79735e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a693ef",
   "metadata": {},
   "source": [
    "# Data processing. Trajectories\n",
    "\n",
    "#### 1. Linear interpolation \n",
    "#### 2. Average two sensors of the same trolley\n",
    "#### 3. Re-label time (t* = t + 1 minute) for the moving average of 2 minutes\n",
    "#### 4. Calculate new temperatures and humidex\n",
    "#### 5. Moving average with s = 1,...,10 minutes \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ebcf07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_interpolation(df):\n",
    "    '''\n",
    "    Function that interpolates linearly the data to have each record separated by 1 second.\n",
    "    \n",
    "    It fills the time \"gaps\" of more than one second with a linear interpolation of the variable (temperature, pressure, etc.). \n",
    "    \n",
    "    '''   \n",
    "    print('The original data-set has {} records'.format(len(df)))\n",
    "    \n",
    "    df.index = df['Time']  # index the column Time\n",
    "    \n",
    "    \n",
    "    \n",
    "    # delete useful columns\n",
    "    del df['Time']\n",
    "    \n",
    "    column_names = ['Typical Part Size[μm]','CO2[ppm]','mass PM2.5[μg/m3]','number PM0.5[#/cm3]','number PM10[#/cm3]','EAQ[]',\n",
    "                   'FAQ[]','O3[ppb]','Radiation[]','Gradient[°C/100m]','BT[dBm]','mass PM1.0[μg/m3]','number PM1.0[#/cm3]',\n",
    "                    'mass PM10[μg/m3]','number PM2.5[#/cm3]','number PM4[#/cm3]']\n",
    "    \n",
    "    for name in column_names:\n",
    "        if name in df:\n",
    "            del df[name]\n",
    "\n",
    "\n",
    "    df=df.resample('1S').asfreq().interpolate()    # Resample the index of times every 1 second (1S) and interpolate linearly\n",
    "    df.reset_index(level=0, inplace=True)  \n",
    "    \n",
    "    print('After interpolating, the new data-set has {} records'.format(len(df)))\n",
    "    print('')\n",
    "    \n",
    "    return df    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "def average_2_sensors(df1,df2):\n",
    "    '''\n",
    "    Function that computes the average quantites of two sensors from the same trolley.\n",
    "    \n",
    "    1. We first need to check that they have the same number of records (and therefore start and end at the same time HH:MM:SS).\n",
    "    2. Afterwards, we compute, at each record (second) the average quantities of latitude, longitude, temperature, pressasure...\n",
    "    3. We create a new Data-Frame with the averaged quantities (keeping the same time column)\n",
    "    \n",
    "    '''    \n",
    "    \n",
    "    # Compare the initial and final times of the two sensors\n",
    "    \n",
    "    initial_time_df1 = df1['Time'].iloc[0]\n",
    "    final_time_df1 = df1['Time'].iloc[-1]\n",
    "    \n",
    "    initial_time_df2 = df2['Time'].iloc[0]\n",
    "    final_time_df2 = df2['Time'].iloc[-1]\n",
    "    \n",
    "    \n",
    "    # We have to keep the largest initial time (later) and the smallest final time (earlier)\n",
    "    # For example, if df1 starts at 13:50:00 and df2 at 13:50:10, then we have to take 13:50:10 for the new data-set, since\n",
    "    # df2 has no data earlier than 13:50:10. On the other hand, if df1 ends at 14:00:10 and df2 at 14:00:15, then we must take\n",
    "    # 14:00:10 as the final time for the new data-set, since df1 has no data later than 14:00:10.\n",
    "    \n",
    "    if initial_time_df1 < initial_time_df2:   \n",
    "        initial_time_df = initial_time_df2 \n",
    "    \n",
    "    elif initial_time_df1 > initial_time_df2:\n",
    "        initial_time_df = initial_time_df1\n",
    "        \n",
    "    else: \n",
    "        initial_time_df = initial_time_df1  # it is irrelevant to take df1 or df2 because both initial times are the same\n",
    "        \n",
    "    \n",
    "    if final_time_df1 < final_time_df2:\n",
    "        final_time_df = final_time_df1\n",
    "    \n",
    "    elif final_time_df1 > final_time_df2:\n",
    "        final_time_df = final_time_df2\n",
    "        \n",
    "    else: \n",
    "        final_time_df = final_time_df1  # it is irrelevant to take df1 or df2 because both final times are the same\n",
    "    \n",
    "    \n",
    "    print('The data-set 1 has {} records, starts at {} and ends at {}'.format(len(df1),initial_time_df1,final_time_df1))\n",
    "    print('The data-set 2 has {} records, starts at {} and ends at {}'.format(len(df2),initial_time_df2,final_time_df2))\n",
    "    \n",
    "    print('So the new data-set starts at {} and ends at {}'.format(initial_time_df,final_time_df))\n",
    "    \n",
    "    \n",
    "    # Cut the data-sets df1 and df2 with the new initial and final times\n",
    "\n",
    "    df1 = df1.loc[(df1['Time'] >= initial_time_df) & (df1['Time'] <= final_time_df )].reset_index()\n",
    "    del df1['index']\n",
    "    \n",
    "    df2 = df2.loc[(df2['Time'] >= initial_time_df) & (df2['Time'] <= final_time_df )].reset_index()\n",
    "    del df2['index']\n",
    "        \n",
    "    \n",
    "    if len(df1) == len(df2):\n",
    "        print('Now both data-sets have the same number of records, which is {}'.format(len(df1)))\n",
    "    \n",
    "    print('')\n",
    "    \n",
    "    # Average each column in a new data-frame\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    df['Time'] = df1['Time']\n",
    "    df['Lat'] = (df1['Lat'] +  df2['Lat'] ) / 2\n",
    "    df['Lon'] = (df1['Lon'] +  df2['Lon'] ) / 2\n",
    "    df['Temp[°C]'] = (df1['Temp[°C]'] +  df2['Temp[°C]'] ) / 2\n",
    "    df['Hum[%]'] = (df1['Hum[%]'] +  df2['Hum[%]'] ) / 2\n",
    "    df['Alt[m]'] = (df1['Alt[m]'] +  df2['Alt[m]'] ) / 2\n",
    "    df['Press[mbar]'] = (df1['Press[mbar]'] +  df2['Press[mbar]'] ) / 2\n",
    "    df['HDX[°C]'] = (df1['HDX[°C]'] +  df2['HDX[°C]'] ) / 2\n",
    "    df['Speed[km/h]'] = (df1['Speed[km/h]'] +  df2['Speed[km/h]'] ) / 2\n",
    "    df['DP[°C]'] = (df1['DP[°C]'] +  df2['DP[°C]'] ) /2\n",
    "    \n",
    "    if 'θ[K]' in df:\n",
    "        df['θ[K]'] = (df1['θ[K]'] +  df2['θ[K]']  ) / 2\n",
    "    \n",
    "    print('')\n",
    "    \n",
    "    return df\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def relabel_time(df):\n",
    "    '''\n",
    "    Function that re-labels the \"Time\" column 1 minute (to the right, so in advance). \n",
    "    The new time of each record is  t(i)* = [ t(i) + 2min ] / 2 \n",
    "    In order words:  t(i)* = t(i) + 1 min\n",
    "    \n",
    "    This is done for the case of using a moving average of 2 minutes (so the new time is reballed just in the middle)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    df['Time(s=2)'] =  pd.to_datetime(df['Time']) + pd.Timedelta(hours=0, minutes=1, seconds=0)   \n",
    "    \n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def new_temperatures_and_humidex(df1,df_fixed):\n",
    "    '''\n",
    "    Function that recalculates two new variables for the temperature and two for the humidex.\n",
    "    \n",
    "    The new quantites are:\n",
    "        1. Substracting the temperature of the fixed-sensor T(t) - T_fixed(t)\n",
    "        2. Same as in 1. but then adding the average temperature of the whole trajectory of the fixed sensor:\n",
    "                T*(t) = T(t) - T_fixed(t) + <T_fixed>\n",
    "    \n",
    "    And the same for Humidex (HDX).\n",
    "    \n",
    "    To do that, we first need to have both data-sets (the fixed sensor and the trajectory) with the same number of records\n",
    "    and starting and ending at the exact time. \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Compare the initial and final times of the two sensors\n",
    "    \n",
    "    initial_time_df1 = df1['Time'].iloc[0]\n",
    "    final_time_df1 = df1['Time'].iloc[-1]\n",
    "    \n",
    "    initial_time_df_fixed = df_fixed['Time'].iloc[0]\n",
    "    final_time_df_fixed = df_fixed['Time'].iloc[-1]\n",
    "    \n",
    "    \n",
    "    # We have to keep the largest initial time (later) and the smallest final time (earlier), as in the case above.\n",
    "        \n",
    "    if initial_time_df1 < initial_time_df_fixed:   \n",
    "        initial_time_df = initial_time_df_fixed\n",
    "    \n",
    "    elif initial_time_df1 > initial_time_df_fixed:\n",
    "        initial_time_df = initial_time_df1\n",
    "        \n",
    "    else: \n",
    "        initial_time_df = initial_time_df1  # it is irrelevant to take df1 or df_fixed because both initial times are the same\n",
    "        \n",
    "    \n",
    "    if final_time_df1 < final_time_df_fixed:\n",
    "        final_time_df = final_time_df1\n",
    "    \n",
    "    elif final_time_df1 > final_time_df_fixed:\n",
    "        final_time_df = final_time_df_fixed\n",
    "        \n",
    "    else: \n",
    "        final_time_df = final_time_df1  # it is irrelevant to take df1 or df_fixed because both final times are the same\n",
    "    \n",
    "    \n",
    "    print('The data-set 1 has {} records, starts at {} and ends at {}'.format(len(df1),initial_time_df1,final_time_df1))\n",
    "    print('The data-set 2 has {} records, starts at {} and ends at {}'.format(len(df_fixed),initial_time_df_fixed,\n",
    "                                                                              final_time_df_fixed))\n",
    "    \n",
    "    print('So the new data-set starts at {} and ends at {}'.format(initial_time_df,final_time_df))       \n",
    "        \n",
    "        \n",
    "    \n",
    "    # Cut the data-sets df1 and df2 with the new initial and final times\n",
    "\n",
    "    df1 = df1.loc[(df1['Time'] >= initial_time_df) & (df1['Time'] <= final_time_df )].reset_index()\n",
    "    del df1['index']\n",
    "    \n",
    "    df_fixed = df_fixed.loc[(df_fixed['Time'] >= initial_time_df) & (df_fixed['Time'] <= final_time_df )].reset_index()\n",
    "    del df_fixed['index']\n",
    "        \n",
    "    \n",
    "    if len(df1) == len(df_fixed):\n",
    "        print('Now both data-sets have the same number of records, which is {}'.format(len(df1)))  \n",
    "        \n",
    "        \n",
    "        \n",
    "    # We create two new columns substracting the temperature and the humidex of the fixed sensor (and add to df1)\n",
    "    \n",
    "    df1['T-T_fixed'] = df1['Temp[°C]'] - df_fixed['Temp[°C]']\n",
    "    df1['HDX-HDX_fixed'] = df1['HDX[°C]'] - df_fixed['HDX[°C]']\n",
    "        \n",
    "        \n",
    "    # We create two new columns substracting the temperature and the humidex of the fixed sensor and adding\n",
    "    # the average T (and HDX) of the fixed sensor over the whole data-set (and add to df1)\n",
    "    \n",
    "    avg_T_fixed = df_fixed['Temp[°C]'].mean()\n",
    "    avg_HDX_fixed = df_fixed['HDX[°C]'].mean()\n",
    "    \n",
    "    df1['T-T_fixed+<T>'] = df1['Temp[°C]'] - df_fixed['Temp[°C]'] + avg_T_fixed\n",
    "    df1['HDX-HDX_fixed+<HDX>'] = df1['HDX[°C]'] - df_fixed['HDX[°C]'] + avg_HDX_fixed\n",
    "    \n",
    "    print('')\n",
    "    \n",
    "    return df1\n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "def moving_avg(window_size, df,temp):\n",
    "    '''\n",
    "    Function that computes the moving average with a window size of \"window_size\" seconds. \n",
    "    \n",
    "    The variable \"temp\" is a string, which is the name of the column of the variable we want to average (for example 'T').\n",
    "    \n",
    "    The moving average is calculated in a time-advanced way. That is, the new variable \"temp*\" at the timestamp t(i) is\n",
    "    the result of averaging all \"temp\" in the window size of [t(i), t(i)+s]. \n",
    "    \n",
    "    For example, if s = 2 seconds:\n",
    "    \n",
    "    t(0) --> T(0) --> T(0)* = [T(0)+T(1)+T(2)] / 3\n",
    "    t(1) --> T(1) --> T(1)* = [T(1)+T(2)+T(3)] / 3\n",
    "    ...\n",
    "    \n",
    "    Therefore, the general formula is, for a given position \"i\":\n",
    "    \n",
    "                        T*(i) = (1/(s+1)) * sum(from j=0 to s) T(j+i)\n",
    "                        \n",
    "    where \"s\" is the time window. \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    i=0\n",
    "    moving_averages = []\n",
    "\n",
    "    while i < len(df) - window_size + 1:\n",
    "\n",
    "        # Variable T, which can be the temperature T, T-Tfixed, HDX...\n",
    "        T = df[temp].tolist()\n",
    "             \n",
    "        # Store elements from i to i+window_size\n",
    "        T_window = T[i : i + window_size]\n",
    "\n",
    "        # Average T of the current window\n",
    "        T_window_avg = sum(T_window) / window_size\n",
    "\n",
    "        # Store the current avg T window\n",
    "        moving_averages.append(T_window_avg)\n",
    "\n",
    "        # Shift window to right by one position\n",
    "        i += 1\n",
    "\n",
    "\n",
    "    # Add NaN values at the end of the list in order to add as a new column in the DataFrame\n",
    "    j=0\n",
    "    while len(moving_averages) < len(df):\n",
    "        moving_averages.append(np.nan)\n",
    "        j += 1    \n",
    "        \n",
    "        \n",
    "    # New column using the variable \"temp\" and the window_size for the name of the column\n",
    "    \n",
    "    df['avg_moving_'+temp+'_'+str(window_size-1)+'s'] = moving_averages\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0d7eed",
   "metadata": {},
   "source": [
    "# Example with data from Fundació Comtal\n",
    "\n",
    "    - Date of the experiment: 11/07/2024\n",
    "    - 5 trolleys with 2 sensors per trolley\n",
    "    - 1 fixed trolley with 2 sensors\n",
    "\n",
    "##  0. Read the data-sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ed292bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trolley 1\n",
    "df_comtal_carro1_sensor1 = pd.read_csv('f_comtal\\\\comtal_10juliol2024_carro1_sensor1.csv')\n",
    "df_comtal_carro1_sensor1.drop_duplicates(subset='Time', keep='first', inplace=True, ignore_index=True)\n",
    "df_comtal_carro1_sensor1['Time'] = pd.to_datetime(df_comtal_carro1_sensor1['Time'], format='%Y-%m-%dT%H:%M:%S%z') \n",
    "df_comtal_carro1_sensor1['Time'] = df_comtal_carro1_sensor1['Time'].dt.tz_localize(None)\n",
    "\n",
    "df_comtal_carro1_sensor2 = pd.read_csv('f_comtal\\\\comtal_10juliol2024_carro1_sensor2.csv')\n",
    "df_comtal_carro1_sensor2.drop_duplicates(subset='Time', keep='first', inplace=True, ignore_index=True)\n",
    "df_comtal_carro1_sensor2['Time'] = pd.to_datetime(df_comtal_carro1_sensor2['Time'], format='%Y-%m-%dT%H:%M:%S%z') \n",
    "df_comtal_carro1_sensor2['Time'] = df_comtal_carro1_sensor2['Time'].dt.tz_localize(None)\n",
    "\n",
    "\n",
    "\n",
    "# Trolley 2\n",
    "df_comtal_carro2_sensor3 = pd.read_csv('f_comtal\\\\comtal_10juliol2024_carro2_sensor3.csv')\n",
    "df_comtal_carro2_sensor3.drop_duplicates(subset='Time', keep='first', inplace=True, ignore_index=True)\n",
    "df_comtal_carro2_sensor3['Time'] = pd.to_datetime(df_comtal_carro2_sensor3['Time'], format='%Y-%m-%dT%H:%M:%S%z') \n",
    "df_comtal_carro2_sensor3['Time'] = df_comtal_carro2_sensor3['Time'].dt.tz_localize(None)\n",
    "\n",
    "df_comtal_carro2_sensor4 = pd.read_csv('f_comtal\\\\comtal_10juliol2024_carro2_sensor4.csv')\n",
    "df_comtal_carro2_sensor4.drop_duplicates(subset='Time', keep='first', inplace=True, ignore_index=True)\n",
    "df_comtal_carro2_sensor4['Time'] = pd.to_datetime(df_comtal_carro2_sensor4['Time'], format='%Y-%m-%dT%H:%M:%S%z') \n",
    "df_comtal_carro2_sensor4['Time'] = df_comtal_carro2_sensor4['Time'].dt.tz_localize(None)\n",
    "\n",
    "\n",
    "\n",
    "# Trolley 3\n",
    "df_comtal_carro3_sensor5 = pd.read_csv('f_comtal\\\\comtal_10juliol2024_carro3_sensor5.csv')\n",
    "df_comtal_carro3_sensor5.drop_duplicates(subset='Time', keep='first', inplace=True, ignore_index=True)\n",
    "df_comtal_carro3_sensor5['Time'] = pd.to_datetime(df_comtal_carro3_sensor5['Time'], format='%Y-%m-%dT%H:%M:%S%z') \n",
    "df_comtal_carro3_sensor5['Time'] = df_comtal_carro3_sensor5['Time'].dt.tz_localize(None)\n",
    "\n",
    "df_comtal_carro3_sensor18 = pd.read_csv('f_comtal\\\\comtal_10juliol2024_carro3_sensor18.csv')\n",
    "df_comtal_carro3_sensor18.drop_duplicates(subset='Time', keep='first', inplace=True, ignore_index=True)\n",
    "df_comtal_carro3_sensor18['Time'] = pd.to_datetime(df_comtal_carro3_sensor18['Time'], format='%Y-%m-%dT%H:%M:%S%z') \n",
    "df_comtal_carro3_sensor18['Time'] = df_comtal_carro3_sensor18['Time'].dt.tz_localize(None)\n",
    "\n",
    "\n",
    "\n",
    "# Trolley 4\n",
    "df_comtal_carro4_sensor7 = pd.read_csv('f_comtal\\\\comtal_10juliol2024_carro4_sensor7.csv')\n",
    "df_comtal_carro4_sensor7.drop_duplicates(subset='Time', keep='first', inplace=True, ignore_index=True)\n",
    "df_comtal_carro4_sensor7['Time'] = pd.to_datetime(df_comtal_carro4_sensor7['Time'], format='%Y-%m-%dT%H:%M:%S%z') \n",
    "df_comtal_carro4_sensor7['Time'] = df_comtal_carro4_sensor7['Time'].dt.tz_localize(None)\n",
    "\n",
    "df_comtal_carro4_sensor8 = pd.read_csv('f_comtal\\\\comtal_10juliol2024_carro4_sensor8.csv')\n",
    "df_comtal_carro4_sensor8.drop_duplicates(subset='Time', keep='first', inplace=True, ignore_index=True)\n",
    "df_comtal_carro4_sensor8['Time'] = pd.to_datetime(df_comtal_carro4_sensor8['Time'], format='%Y-%m-%dT%H:%M:%S%z') \n",
    "df_comtal_carro4_sensor8['Time'] = df_comtal_carro4_sensor8['Time'].dt.tz_localize(None)\n",
    "\n",
    "\n",
    "\n",
    "# Trolley 5\n",
    "df_comtal_carro5_sensor9 = pd.read_csv('f_comtal\\\\comtal_10juliol2024_carro5_sensor9.csv')\n",
    "df_comtal_carro5_sensor9.drop_duplicates(subset='Time', keep='first', inplace=True, ignore_index=True)\n",
    "df_comtal_carro5_sensor9['Time'] = pd.to_datetime(df_comtal_carro5_sensor9['Time'], format='%Y-%m-%dT%H:%M:%S%z') \n",
    "df_comtal_carro5_sensor9['Time'] = df_comtal_carro5_sensor9['Time'].dt.tz_localize(None)\n",
    "\n",
    "df_comtal_carro5_sensor10 = pd.read_csv('f_comtal\\\\comtal_10juliol2024_carro5_sensor10.csv')\n",
    "df_comtal_carro5_sensor10.drop_duplicates(subset='Time', keep='first', inplace=True, ignore_index=True)\n",
    "df_comtal_carro5_sensor10['Time'] = pd.to_datetime(df_comtal_carro5_sensor10['Time'], format='%Y-%m-%dT%H:%M:%S%z') \n",
    "df_comtal_carro5_sensor10['Time'] = df_comtal_carro5_sensor10['Time'].dt.tz_localize(None)\n",
    "\n",
    "\n",
    "\n",
    "# Trolley fixed\n",
    "df_comtal_carro_fix_sensor15 = pd.read_csv('f_comtal\\\\comtal_10juliol2024_carro_fix_sensor15.csv')\n",
    "df_comtal_carro_fix_sensor15.drop_duplicates(subset='Time', keep='first', inplace=True, ignore_index=True)\n",
    "df_comtal_carro_fix_sensor15['Time'] = pd.to_datetime(df_comtal_carro_fix_sensor15['Time'], format='%Y-%m-%dT%H:%M:%S%z') \n",
    "df_comtal_carro_fix_sensor15['Time'] = df_comtal_carro_fix_sensor15['Time'].dt.tz_localize(None)\n",
    "\n",
    "df_comtal_carro_fix_sensor17 = pd.read_csv('f_comtal\\\\comtal_10juliol2024_carro_fix_sensor17.csv')\n",
    "df_comtal_carro_fix_sensor17.drop_duplicates(subset='Time', keep='first', inplace=True, ignore_index=True)\n",
    "df_comtal_carro_fix_sensor17['Time'] = pd.to_datetime(df_comtal_carro_fix_sensor17['Time'], format='%Y-%m-%dT%H:%M:%S%z') \n",
    "df_comtal_carro_fix_sensor17['Time'] = df_comtal_carro_fix_sensor17['Time'].dt.tz_localize(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed41455",
   "metadata": {},
   "source": [
    "## 1. Linear interpolation\n",
    "\n",
    "All the records equally spaced by 1 second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "129bce7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original data-set has 4879 records\n",
      "After interpolating, the new data-set has 6914 records\n",
      "\n",
      "The original data-set has 4898 records\n",
      "After interpolating, the new data-set has 6914 records\n",
      "\n",
      "The original data-set has 4897 records\n",
      "After interpolating, the new data-set has 6949 records\n",
      "\n",
      "The original data-set has 4902 records\n",
      "After interpolating, the new data-set has 6945 records\n",
      "\n",
      "The original data-set has 5068 records\n",
      "After interpolating, the new data-set has 7189 records\n",
      "\n",
      "The original data-set has 4999 records\n",
      "After interpolating, the new data-set has 7070 records\n",
      "\n",
      "The original data-set has 5080 records\n",
      "After interpolating, the new data-set has 7225 records\n",
      "\n",
      "The original data-set has 5065 records\n",
      "After interpolating, the new data-set has 7215 records\n",
      "\n",
      "The original data-set has 5329 records\n",
      "After interpolating, the new data-set has 7539 records\n",
      "\n",
      "The original data-set has 5313 records\n",
      "After interpolating, the new data-set has 7526 records\n",
      "\n",
      "The original data-set has 5350 records\n",
      "After interpolating, the new data-set has 7590 records\n",
      "\n",
      "The original data-set has 5208 records\n",
      "After interpolating, the new data-set has 7394 records\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_comtal_carro1_sensor1 = linear_interpolation(df_comtal_carro1_sensor1)\n",
    "df_comtal_carro1_sensor2 = linear_interpolation(df_comtal_carro1_sensor2)\n",
    "\n",
    "df_comtal_carro2_sensor3 = linear_interpolation(df_comtal_carro2_sensor3)\n",
    "df_comtal_carro2_sensor4 = linear_interpolation(df_comtal_carro2_sensor4)\n",
    "\n",
    "df_comtal_carro3_sensor5 = linear_interpolation(df_comtal_carro3_sensor5)\n",
    "df_comtal_carro3_sensor18 = linear_interpolation(df_comtal_carro3_sensor18)\n",
    "\n",
    "df_comtal_carro4_sensor7 = linear_interpolation(df_comtal_carro4_sensor7)\n",
    "df_comtal_carro4_sensor8 = linear_interpolation(df_comtal_carro4_sensor8)\n",
    "\n",
    "df_comtal_carro5_sensor9 = linear_interpolation(df_comtal_carro5_sensor9)\n",
    "df_comtal_carro5_sensor10 = linear_interpolation(df_comtal_carro5_sensor10)\n",
    "\n",
    "df_comtal_carro_fix_sensor15 = linear_interpolation(df_comtal_carro_fix_sensor15)\n",
    "df_comtal_carro_fix_sensor17 = linear_interpolation(df_comtal_carro_fix_sensor17)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5ad92d",
   "metadata": {},
   "source": [
    "##  2. Average two sensors of the same trolley\n",
    "\n",
    "Create a new data-set with the average quantites (coordinates, temperature, humidity...) of the two sensors from the same trolley, using the later start time and the earlier end time of the two. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "dc3d69c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data-set 1 has 6914 records, starts at 2024-07-10 14:51:08 and ends at 2024-07-10 16:46:21\n",
      "The data-set 2 has 6914 records, starts at 2024-07-10 14:51:12 and ends at 2024-07-10 16:46:25\n",
      "So the new data-set starts at 2024-07-10 14:51:12 and ends at 2024-07-10 16:46:21\n",
      "Now both data-sets have the same number of records, which is 6910\n",
      "\n",
      "\n",
      "The data-set 1 has 6949 records, starts at 2024-07-10 14:50:43 and ends at 2024-07-10 16:46:31\n",
      "The data-set 2 has 6945 records, starts at 2024-07-10 14:50:50 and ends at 2024-07-10 16:46:34\n",
      "So the new data-set starts at 2024-07-10 14:50:50 and ends at 2024-07-10 16:46:31\n",
      "Now both data-sets have the same number of records, which is 6942\n",
      "\n",
      "\n",
      "The data-set 1 has 7189 records, starts at 2024-07-10 14:47:04 and ends at 2024-07-10 16:46:52\n",
      "The data-set 2 has 7070 records, starts at 2024-07-10 14:49:04 and ends at 2024-07-10 16:46:53\n",
      "So the new data-set starts at 2024-07-10 14:49:04 and ends at 2024-07-10 16:46:52\n",
      "Now both data-sets have the same number of records, which is 7069\n",
      "\n",
      "\n",
      "The data-set 1 has 7225 records, starts at 2024-07-10 14:46:35 and ends at 2024-07-10 16:46:59\n",
      "The data-set 2 has 7215 records, starts at 2024-07-10 14:46:42 and ends at 2024-07-10 16:46:56\n",
      "So the new data-set starts at 2024-07-10 14:46:42 and ends at 2024-07-10 16:46:56\n",
      "Now both data-sets have the same number of records, which is 7215\n",
      "\n",
      "\n",
      "The data-set 1 has 7539 records, starts at 2024-07-10 14:41:57 and ends at 2024-07-10 16:47:35\n",
      "The data-set 2 has 7526 records, starts at 2024-07-10 14:42:08 and ends at 2024-07-10 16:47:33\n",
      "So the new data-set starts at 2024-07-10 14:42:08 and ends at 2024-07-10 16:47:33\n",
      "Now both data-sets have the same number of records, which is 7526\n",
      "\n",
      "\n",
      "The data-set 1 has 7590 records, starts at 2024-07-10 14:40:55 and ends at 2024-07-10 16:47:24\n",
      "The data-set 2 has 7394 records, starts at 2024-07-10 14:44:16 and ends at 2024-07-10 16:47:29\n",
      "So the new data-set starts at 2024-07-10 14:44:16 and ends at 2024-07-10 16:47:24\n",
      "Now both data-sets have the same number of records, which is 7389\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_comtal_carro1 = average_2_sensors(df_comtal_carro1_sensor1,df_comtal_carro1_sensor2)\n",
    "\n",
    "df_comtal_carro2 = average_2_sensors(df_comtal_carro2_sensor3,df_comtal_carro2_sensor4)\n",
    "\n",
    "df_comtal_carro3 = average_2_sensors(df_comtal_carro3_sensor5,df_comtal_carro3_sensor18)\n",
    "\n",
    "df_comtal_carro4 = average_2_sensors(df_comtal_carro4_sensor7,df_comtal_carro4_sensor8)\n",
    "\n",
    "df_comtal_carro5 = average_2_sensors(df_comtal_carro5_sensor9,df_comtal_carro5_sensor10)\n",
    "\n",
    "df_comtal_carro_fix = average_2_sensors(df_comtal_carro_fix_sensor15,df_comtal_carro_fix_sensor17)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a8e381",
   "metadata": {},
   "source": [
    "## 3. Re-label time (t* = t + 1 minute) for the moving average of 2 minutes\n",
    "Create a new column with the time advanced 1 minute. This is done because we perform a moving average of 2 minutes (then the new timestamp is in the middle). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3fcca3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comtal_carro1 = relabel_time(df_comtal_carro1)\n",
    "df_comtal_carro2 = relabel_time(df_comtal_carro2)\n",
    "df_comtal_carro3 = relabel_time(df_comtal_carro3)\n",
    "df_comtal_carro4 = relabel_time(df_comtal_carro4)\n",
    "df_comtal_carro5 = relabel_time(df_comtal_carro5)\n",
    "df_comtal_carro_fix = relabel_time(df_comtal_carro_fix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e86275",
   "metadata": {},
   "source": [
    "## 4. Calculate new temperatures and humidex\n",
    "Create 4 new columns (2 for temperature and 2 for humidex), which are:\n",
    "    \n",
    "    1. T - T_fixed. Substracting the temperature of the fixed sensor at each second (location)\n",
    "    2. T - T_fixed + <T>. Same as 1, but then adding the average temperature of the fixed sensor (over all time)   \n",
    "    3. HDX - HDX_fixed. Substracting the humidex of the fixed sensor at each second (location)\n",
    "    3. HDX - HDX_fixed + <HDX>. Same as 1, but then adding the average humidex of the fixed sensor (over all time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "798b2b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data-set 1 has 6910 records, starts at 2024-07-10 14:51:12 and ends at 2024-07-10 16:46:21\n",
      "The data-set 2 has 7389 records, starts at 2024-07-10 14:44:16 and ends at 2024-07-10 16:47:24\n",
      "So the new data-set starts at 2024-07-10 14:51:12 and ends at 2024-07-10 16:46:21\n",
      "Now both data-sets have the same number of records, which is 6910\n",
      "\n",
      "The data-set 1 has 6942 records, starts at 2024-07-10 14:50:50 and ends at 2024-07-10 16:46:31\n",
      "The data-set 2 has 7389 records, starts at 2024-07-10 14:44:16 and ends at 2024-07-10 16:47:24\n",
      "So the new data-set starts at 2024-07-10 14:50:50 and ends at 2024-07-10 16:46:31\n",
      "Now both data-sets have the same number of records, which is 6942\n",
      "\n",
      "The data-set 1 has 7069 records, starts at 2024-07-10 14:49:04 and ends at 2024-07-10 16:46:52\n",
      "The data-set 2 has 7389 records, starts at 2024-07-10 14:44:16 and ends at 2024-07-10 16:47:24\n",
      "So the new data-set starts at 2024-07-10 14:49:04 and ends at 2024-07-10 16:46:52\n",
      "Now both data-sets have the same number of records, which is 7069\n",
      "\n",
      "The data-set 1 has 7215 records, starts at 2024-07-10 14:46:42 and ends at 2024-07-10 16:46:56\n",
      "The data-set 2 has 7389 records, starts at 2024-07-10 14:44:16 and ends at 2024-07-10 16:47:24\n",
      "So the new data-set starts at 2024-07-10 14:46:42 and ends at 2024-07-10 16:46:56\n",
      "Now both data-sets have the same number of records, which is 7215\n",
      "\n",
      "The data-set 1 has 7526 records, starts at 2024-07-10 14:42:08 and ends at 2024-07-10 16:47:33\n",
      "The data-set 2 has 7389 records, starts at 2024-07-10 14:44:16 and ends at 2024-07-10 16:47:24\n",
      "So the new data-set starts at 2024-07-10 14:44:16 and ends at 2024-07-10 16:47:24\n",
      "Now both data-sets have the same number of records, which is 7389\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_comtal_carro1 = new_temperatures_and_humidex(df_comtal_carro1,df_comtal_carro_fix)\n",
    "df_comtal_carro2 = new_temperatures_and_humidex(df_comtal_carro2,df_comtal_carro_fix)\n",
    "df_comtal_carro3 = new_temperatures_and_humidex(df_comtal_carro3,df_comtal_carro_fix)\n",
    "df_comtal_carro4 = new_temperatures_and_humidex(df_comtal_carro4,df_comtal_carro_fix)\n",
    "df_comtal_carro5 = new_temperatures_and_humidex(df_comtal_carro5,df_comtal_carro_fix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c133c0d5",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Moving average with s = 1,...,10 minutes \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fe202bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "temps = ['Temp[°C]','HDX[°C]','T-T_fixed','HDX-HDX_fixed','T-T_fixed+<T>','HDX-HDX_fixed+<HDX>']\n",
    "window_sizes = [61,121,181,241,301,361,421,481,541,601]\n",
    "\n",
    "for temp in temps:\n",
    "    for window_size in window_sizes:\n",
    "        df_comtal_carro1 = moving_avg(window_size, df_comtal_carro1,temp)\n",
    "        df_comtal_carro2 = moving_avg(window_size, df_comtal_carro2,temp)\n",
    "        df_comtal_carro3 = moving_avg(window_size, df_comtal_carro3,temp)\n",
    "        df_comtal_carro4 = moving_avg(window_size, df_comtal_carro4,temp)\n",
    "        df_comtal_carro5 = moving_avg(window_size, df_comtal_carro5,temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b971b5d8",
   "metadata": {},
   "source": [
    "## Save new data-frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "962d45b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_comtal_carro1.to_csv('f_comtal\\\\df_comtal_carro1.csv',index=False)\n",
    "#df_comtal_carro2.to_csv('f_comtal\\\\df_comtal_carro2.csv',index=False)\n",
    "#df_comtal_carro3.to_csv('f_comtal\\\\df_comtal_carro3.csv',index=False)\n",
    "#df_comtal_carro4.to_csv('f_comtal\\\\df_comtal_carro4.csv',index=False)\n",
    "#df_comtal_carro5.to_csv('f_comtal\\\\df_comtal_carro5.csv',index=False)\n",
    "#df_comtal_carro_fix.to_csv('f_comtal\\\\df_comtal_carro_fix.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
